{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9d0388",
   "metadata": {},
   "source": [
    "1. **Le Principe Fondamental : La \"Table Infinie\"**  \n",
    "Le concept de Spark Structured Streaming est de traiter un flux de données non pas comme une séquence de paquets, mais comme une table qui grandit à l'infini (Unbounded Table).  \n",
    "Concept : Chaque nouvelle donnée arrivant d'un capteur est simplement une nouvelle ligne ajoutée (\"appended\") à cette table virtuelle.\n",
    "Utilité SmartTech : Cela nous permet d'utiliser le même code et la même logique SQL que pour nos analyses historiques (Batch). Pas besoin d'apprendre un nouveau langage pour le temps réel.  \n",
    "\n",
    "2. **Lecture et Écriture de Flux**  \n",
    "Contrairement au traitement par lots (Batch) qui a un début et une fin, le streaming est continu.\n",
    "API : On utilise spark.readStream pour définir la source et df.writeStream pour démarrer le traitement.\n",
    "Sources supportées :\n",
    "- Kafka : Le standard pour ingérer nos millions de messages IoT.\n",
    "- Files (Fichiers) : Pour surveiller l'arrivée de nouveaux fichiers CSV/JSON dans un dossier.\n",
    "- Sinks (Destinations) supportés :\n",
    "- Kafka : Pour renvoyer des alertes vers d'autres services.\n",
    "- Delta Lake : Pour stocker l'historique fiable.\n",
    "- Console/Memory : Pour le débogage.  \n",
    "\n",
    "3. **Le Rythme du Traitement : Les Triggers**  \n",
    "Le Trigger définit quand Spark doit vérifier s'il y a de nouvelles données et lancer le calcul.\n",
    "ProcessingTime (Défaut) : \"Vérifie toutes les X secondes\". Idéal pour nos tableaux de bord de monitoring (latence ~100ms à quelques secondes).\n",
    "Once / AvailableNow : \"Traite tout ce qui est en attente, puis éteins-toi\". Parfait pour réduire les coûts cloud si on n'a besoin de mettre à jour les données que toutes les heures.\n",
    "Continuous (Expérimental) : Pour une latence ultra-faible (milliseconde), mais avec des limitations techniques.\n",
    "\n",
    "4. **Gestion du Temps et des Retards (Windowing & Watermarks)**  \n",
    "En IoT, les problèmes de réseau sont fréquents. Une donnée de 10h00 peut arriver à 10h05.\n",
    "Windowing (Fenêtrage) : Permet d'agréger les données par tranches de temps (ex: \"Moyenne de température par tranche de 5 minutes\") plutôt que par heure d'arrivée technique.\n",
    "Watermarks (Fil d'eau) : C'est le seuil de tolérance. On dit au système : \"Accepte les données en retard jusqu'à 10 minutes. Au-delà, ignore-les pour ne pas surcharger la mémoire.\" C'est crucial pour la stabilité de nos serveurs.\n",
    "\n",
    "5. **Modes de Sortie (Output Modes)**  \n",
    "Comment mettre à jour le résultat quand de nouvelles données arrivent ?\n",
    "Append (Ajout) : On ajoute seulement les nouvelles lignes.\n",
    "Usage SmartTech : Stockage brut des messages des capteurs.\n",
    "Update (Mise à jour) : On met à jour les lignes qui ont changé.\n",
    "Usage SmartTech : Maintien de la \"dernière température connue\" pour chaque machine.\n",
    "Complete (Complet) : On réécrit tout le tableau à chaque fois.\n",
    "Usage SmartTech : Compteurs simples (ex: \"Nombre total d'erreurs depuis le démarrage\"), à éviter sur de gros volumes.\n",
    "\n",
    "6. **Fiabilité : Checkpointing et Tolérance aux Pannes**  \n",
    "C'est l'assurance-vie du pipeline de données.\n",
    "Checkpointing : Spark sauvegarde régulièrement sa progression (offsets) et son état intermédiaire sur un stockage durable (HDFS/S3).\n",
    "Garantie : En cas de crash du serveur, Spark redémarre, lit le checkpoint et reprend exactement là où il s'est arrêté. Cela garantit une sémantique \"Exactly-once\" (aucune donnée perdue, aucune donnée comptée deux fois), indispensable pour la facturation ou la maintenance prédictive.\n",
    "\n",
    "7. **Architecture Médaillon (Best Practice)**  \n",
    "Pour organiser ce flux de données, nous adoptons une architecture en couches :\n",
    "Couche\n",
    "Rôle chez SmartTech\n",
    "Mode Spark\n",
    "- BRONZE  \n",
    "Zone d'atterrissage. Données brutes (Raw), ingérées depuis Kafka sans modification. Permet de \"rejouer\" l'histoire en cas de bug.\n",
    "Append\n",
    "- SILVER  \n",
    "Zone de nettoyage. Données filtrées, dédupliquées et typées (Schéma validé). C'est la source de vérité propre.\n",
    "Append / Update\n",
    "- GOLD  \n",
    "Zone métier. Données agrégées prêtes pour la consommation (KPIs, Moyennes horaires pour BI).\n",
    "Complete / Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5820a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
